# BlindSys: Assisting the Visually Impaired in Multi-object Scene Description Using OWA-Based Fusion of CNN Models
Advances in technology can provide a lot of support for visually impaired (VI) persons. In particular, computer vision and machine learning can provide solutions for object detection and recognition. In this work, we propose a multi-label image classification solution for assisting a VI person in recognizing the presence of multiple objects in a scene. The solution is based on the fusion of two deep CNN models using the induced Ordered Weighted Averaging (OWA) approach. Namely, in this work, we fuse the outputs of two pre-trained CNN models, VGG16 and SqueezeNet. To use the induced OWA approach we need to estimate a confidence measure in the outputs of the two CNN base models. To this end, we propose the residual error between the predicted output and the true output as a measure of confidence. We estimate this residual error using another dedicated CNN model that is trained on the residual errors computed from the main CNN models. Then the OAW technique uses these estimated residual errors as confidence measures and fuses the decisions of the two main CNN models. When tested on four image datasets of indoor environments from two separate locations, the proposed novel method improves the detection accuracy compared to both base CNN models. The results are also significantly better than state-of-the-art methods reported in the literature. 

Published paper:
Alhichri, H., Bazi, Y. & Alajlan, N. Assisting the Visually Impaired in Multi-object Scene Description Using OWA-Based Fusion of CNN Models. Arab J Sci Eng (2020). https://doi.org/10.1007/s13369-020-04799-7
https://link.springer.com/article/10.1007/s13369-020-04799-7
